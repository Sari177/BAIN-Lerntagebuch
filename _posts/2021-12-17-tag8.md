---
title: "Tag 8 - Linked Data "
date: 2021-12-17
---

In der letzten Lehrveranstaltung lagen die Schwerpunkte auf folgende Themen:

- Nachtrag zu Metadaten modellieren und Schnittstellen nutzen
  - Motivation
  - Vergleich mit anderen Tools
- Suchmaschinen und Discovery-Systeme

Heute gab es wieder ein paar Kommentare zu unseren Lerntagebüchern und wir beschäftigten uns anfangs nochmals mit dem Thema Metadaten modellieren und Schnittstellen nutzen. Hierzu gab es ein Vergleich mit anderen Tools.
OpenRefine wo wir kennengelernt haben, hat eine Benutzeroberfläche, was sehr hilfreich sein kann. Dadurch können Transformationsschritte einfacher nachvollziehbar sein, da man nach hinten und nach vorne springen kann. Auch komplexe Transformationen können erstellt werden mit unterschiedlichen Sprachen ( GREL, Jython, Clojure).
In der Praxis werden auch oft andere Software benutzt. Oft wird die Entscheidung, welche Software benutzt wird, durch die bereits erworbenen Kenntnisse gefällt. Es ist aber auch sehr zu empfehlen, dass man analysiert, was die Tools können und welche Anforderungen der Betrieb dazu hat. Das richtige Werkzeug sollte für die gegebene Aufgabe gewählt werden. In der Praxis macht man halt oft Kompromisse, da unterschiedliche Leute unterschiedliche Kenntnisse und Erfahrungen gemacht haben. 
Alternative Software:
- Catmandu (Perl)
- Metafacture (Java) – kann auch als Programmbibliothek benutzt werden und in die eigene Software eingebaut werden
- MarcEdit (für MARC21)
- Pandas (Python)
Pandas kenne ich bereits auch durch ein anderes Modul, als wir dynamische Interfaces entwickelt haben.

In den letzten Lehreinheiten haben wir hauptsächlich mit XML Dateien gearbeitet. Da es mit abstand das verbreitete Austauschformat ist in Bibliothek und Archivsystemen. Aber es ergab sich auch immer mehr ein Wechsel Richtung JSON. Dies ist auch ein Strukturiertes Format, aber es ist sehr viel einfacher gehalten. Da man Felder auch verschachteln kann und es die Begrifflichkeiten können beliebiger verwendet werden.  JSON lässt sich ebenso wie XML im Browser öffnen und anschauen und kann maschinell verarbeitet werden.
Im Browser kann am Ende der URL einfach «.json» oder «&format=json» eingegeben werden und man kann die Webseite im JSON Format betrachtet werden. So kann dieser Datensatz für ein Programm als JSON Format weiterverarbeitet werden.
Zum Beispiel bei einer automatisch generierten Suchabfrage, kann im Hintergrund mit einem JavaSkript über die API übergeben und durch die ID wird der Datensatz für den Benutzer sichtbar zurückgegeben. 
Bei einer JSON API muss man sich immer mit den Schnittstellen beschäftigen, da die Felder individuell gehandhabt werden (auch innerhalb einer gleichen Unternehmung wie Google). Auf der Seite «https://scrapir.org» können sogar die Code snippets herauskopiert werden um die API verwenden zu können.
Suchmaschine und Discovery Systeme
In der letzten Sitzung haben wir VuFind heruntergeladen. Das Discovery-System VuFind basiert auf Solr und kann sich auf mehreren Core beziehen (authority, biblio, reserves, website). Die Administrationsoberfläche kann unter dem localhost im Browser aufgerufen werden mit dem Port 8983 (  http://localhost:8983). Vor dem Import der Daten wird ein Schema festgelegt, welche Felder existieren und welche Datentypen (integer, boolean, string etc.) diese beinhalten. Solr API (Application programming interface, also Programmschnittstelle auf Deutsch) ist eine selektive Suchmaschine, welche sich nicht auf Archiv oder Bibliotheken beziehen, sondern fürs Web Allgemein. Zum Beispiel Netflix verwendet auch Solr für die Suche. 
Unterschied von Suchindex zu einer Datenbank (zum Beispiel MySQL):
Solr (Suchindex)
- flache Dokumente (für schnelle Datensuche mit einem Suchindex)
-	Suchabfrage: lexikalische Suche (Sinngemäss interpretierbar von z.B. Verb zu Nomen etc.)
-	Keine Konsistenzprüfung
-	Statische Daten
-	Für Retrieval (Suche) geeignet

MySQL (Datenbank
-	relationale Datensätze (mehrere Tabellen in Relation)
-	Suchabfrage: reiner Glyphenvergleich (Zeichen werden 1 zu 1 in der Datenbank gesucht)
-	Transaktionssicherheit
-	Veränderliche Daten
-	Für Storage (CRUD = Create, Read, Update, Delete) geeignet

Im Unterricht untersuchten wir noch die Unterschiede einer Suche zwischen VuFind und Solr. In unserer Gruppe kam folgendes heraus: 
- Beiden Orten gleiche Treffer in gleicher Reihenfolge gefunden
- In Solr erscheint der ganze Datensatz und in VuVind erscheint ein gefilteretere Version des Datensatzes und erscheint dadurch viel struckturierter und mit einer ansprechenden grafischen Oberfläche.
- VuFind hat grafische Oberfläche und ist darum besser lesbar als Solr, wo der Code ausgegeben wird

Danach haben wir noch eine Übung zur Datenintegration gemacht. Das Ziel war einen Import der MarcEdit und Openrefine konvertiertten Daten aus Koha, ArchivesSpace, DSpace und DOAJ in VuFind.
